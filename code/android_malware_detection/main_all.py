# coding=utf-8
import os
from multiprocessing import Pool
from Decompilation.apktool import apktool
from Decompilation.jar2java import jar2java
from LiteRadar.filter_dex import filter_dex
from static import get_apk_path, get_lsi_config, get_xgboost_config, get_cscg_config, get_graph_config
from static import total_process_multi_core, total_process_single_core, java_src_tmp_path, ts_max, min_k_tmp_file
from lexical_analysis.extract_token import extract_token
from Permission.permissionExtract import extractPermission
from dataset_construct.create_filelist import create_filelist
from lsi.lsi import lsi_train, lsi_test
from xgb_classification.combine_lsi_permission import combine_lsi_permission
from xgb_classification.xgboost_clf import train_xgb_model, test_xgb_model
from CSCG.calculate_min_k import calculate_min_k
from CSCG.java_graph import get_cscg_dataset
from GAT.create_graph_dataset import create_graph_files
from GAT.graph_net import graph_model

program_root = os.getcwd()
# 添加apktool的环境变量
os.environ["PATH"] = program_root + '/tools/apktool/' + ":" + os.environ["PATH"]
# 添加jadx的环境变量
os.environ["PATH"] = program_root + '/tools/jadx/build/jadx/bin/' + ":" + os.environ["PATH"]

# 对原始APK文件进行预处理，包括反编译、三方库过滤等,在python2.7下运行
def literadar(dataset):
    # 1. 获取数据集的配置
    apk_path, manifest_path, dex_path, java_path, _3rd_path, permission_path, token_path, filelist_train, filelist_test, filelist_train_filter, filelist_test_filter = get_apk_path(dataset)

    # 2.使用LiteRadar获取每个apk文件的三方库,在python2.7下运行
    filter_dex(apk_path, _3rd_path, total_process_multi_core)

# 对原始APK文件进行预处理，包括反编译、三方库过滤等,在python3.6下运行
def preproces(dataset):
    apk_path, manifest_path, dex_path, java_path, _3rd_path, permission_path, token_path, filelist_train, filelist_test, filelist_train_filter, filelist_test_filter = get_apk_path(dataset)

    # 2.使用apktool获取每个文件的Androidmanifest.xml和class.dex,在python2.7下运行
    apktool(apk_path, manifest_path, dex_path, total_process_multi_core)
    # 3.使用jadx对每个class.dex进行反编译，并将反编译的全部java文件打包生成.zip的压缩包,在python3.6下运行
    jar2java(dex_path, java_path, java_src_tmp_path, program_root, total_process_multi_core)

    # 4.对每个反编译得到的java文件进行token提取,在python3.6下运行
    extract_token(dataset, _3rd_path, java_path, manifest_path, token_path, total_process_single_core)

    # 5.对每个manifest文件提取权限特征,在python3.6下运行
    extractPermission(manifest_path, permission_path)

    # 6.生成记录每个数据集下全部有效数据的文件filelist.txt,在python3.6下运行
    create_filelist(filelist_train, filelist_train_filter, _3rd_path, manifest_path, java_path)

    # 7.生成记录每个数据集下全部有效数据的文件filelist.txt,在python3.6下运行
    create_filelist(filelist_test, filelist_test_filter, _3rd_path, manifest_path, java_path)


# 在python3.6下运行
# 仅使用语义模型和permission特征进行模型训练
def lsi_model_train(dataset):
    # 8.获取lsi模型训练所需全部文件的路径
    train_file, test_file, TFIDF_dict_path, dict_corpus, TFIDF_model_path, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, LSI_corpus_path_test, token_root, apktool_root_path, no_below, no_above = get_lsi_config(dataset)

    # 9.进行LSI模型的训练，内部包含TFIDF模型的训练，并生成训练特征文件
    lsi_train(dataset, train_file, TFIDF_dict_path, dict_corpus, TFIDF_model_path, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, token_root, no_below=no_below, no_above=no_above)

    # 10.生成测试集的特征向量
    lsi_test(dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root)

    # 11.获取数据集与模型的相关信息
    LSI_Permission_file, LSI_Permission_file_test, lsi_per_xgboost_model, LSI_corpus_path, LSI_corpus_path_test, permission_dir_path = get_xgboost_config(dataset)

    # 12.生成lsi和permission拼接后训练集的特征
    combine_lsi_permission(dataset, LSI_corpus_path, permission_dir_path, LSI_Permission_file)

    # 13.生成测试集的lsi与permission拼接特征
    combine_lsi_permission(dataset, LSI_corpus_path_test, permission_dir_path, LSI_Permission_file_test)

    # 14.训练XGBoost模型进行分类
    train_xgb_model(LSI_Permission_file, lsi_per_xgboost_model)

    # 15.测试XGBoost模型的效果
    test_xgb_model(LSI_Permission_file_test, lsi_per_xgboost_model)


# 基于java文件的import关系进行图构建，相当于public class的调用关系，并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100
def class_set_call_graph(dataset):
    # dataset_name 数据集的名称,
    # java_path 原始java代码压缩包的存放路径,
    # java_graph_path 保存class-set call graph调用关系的路径,
    # _3rd_path 三方库文件的存放路径,
    # token_file_root 保存每个class-set的此法分析得到的tokens,
    # min_k 该数据集下的min_k值
    # 16.获取CSCG的配置信息
    java_path, java_graph_path, _3rd_path, token_file_root= get_cscg_config(dataset)
    train_file, test_file, TFIDF_dict_path, dict_corpus, TFIDF_model_path, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, LSI_corpus_path_test, token_root, apktool_root_path, no_below, no_above = get_lsi_config(dataset, type='cscg')

    # 17.计算min_k
    min_k = calculate_min_k(dataset, java_path, train_file, ts_max, min_k_tmp_file)

    # 18.计算CSCG调用图，并对节点进行分词
    get_cscg_dataset(dataset, java_path, java_graph_path, _3rd_path, token_file_root, min_k=min_k, total_process=total_process_single_core)

    # 提取class-set的LSI向量，每个APK保存成一个文件
    pool = Pool(processes=2)
    # 19.生成训练集的节点特征向量
    # lsi_test(dataset, train_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path, token_root, type='cscg')
    pool.apply_async(lsi_test, (dataset, train_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path, token_root, 'cscg'))

    # 20.生成测试集的节点特征向量
    # lsi_test(dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root, type='cscg')
    pool.apply_async(lsi_test, (dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root, 'cscg'))
    pool.close()
    pool.join()

    # raise Exception
    # 防止多次调参时，读取碎文件太耗时间，因此先将CSCG保存成大文件
    pool = Pool(processes=2)

    # 21.读取PSCN的输入graph源文件
    train_file, test_file, LSI_corpus_path, LSI_corpus_path_test, graph_file_root, model_root, permission_feature_path, lsi_fearue_file, lsi_fearue_file_test = get_graph_config(
        dataset)

    # 22.生成训练集的graph文件
    # create_graph_files(train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path=permission_feature_path, type='cscg', apktool_root_path=apktool_root_path, add_root=False)
    pool.apply_async(create_graph_files, (train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path, 'cscg', apktool_root_path, False))

    # 23.生成测试集的graph文件
    # create_graph_files(test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path=permission_feature_path, type='cscg',  apktool_root_path=apktool_root_path)
    pool.apply_async(create_graph_files, (test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path, 'cscg', apktool_root_path, False))
    pool.close()
    pool.join()

# 基于java文的import关系进行图构建，相当于public class的调用关系，并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100
def class_set_call_graph_test():
    # 12.读取PSCN的输入graph源文件
    train_file, test_file, LSI_corpus_path, LSI_corpus_path_test, graph_file_root, model_root, permission_feature_path, lsi_fearue_file, lsi_fearue_file_test = get_graph_config(dataset)

    # 15.graph_net训练测试
    graph_model(model_root, dataset)

if __name__ == '__main__':
    dataset = 'AMD_AndroZoo'
    # literadar(dataset)
    preproces(dataset)
    lsi_model_train(dataset)
    class_set_call_graph(dataset)
    class_set_call_graph_test()